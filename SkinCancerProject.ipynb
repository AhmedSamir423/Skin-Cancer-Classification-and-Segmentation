{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata Shape: (10015, 8)\n",
      "\n",
      "First few rows of metadata:\n",
      "          image  MEL   NV  BCC  AKIEC  BKL   DF  VASC label\n",
      "0  ISIC_0024306  0.0  1.0  0.0    0.0  0.0  0.0   0.0    NV\n",
      "1  ISIC_0024307  0.0  1.0  0.0    0.0  0.0  0.0   0.0    NV\n",
      "2  ISIC_0024308  0.0  1.0  0.0    0.0  0.0  0.0   0.0    NV\n",
      "3  ISIC_0024309  0.0  1.0  0.0    0.0  0.0  0.0   0.0    NV\n",
      "4  ISIC_0024310  1.0  0.0  0.0    0.0  0.0  0.0   0.0   MEL\n"
     ]
    }
   ],
   "source": [
    "# Load the metadata (labels)\n",
    "metadata_path = \"../HAM10000/GroundTruth.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "print(\"Metadata Shape:\", metadata.shape)\n",
    "metadata[\"label\"] = metadata[classes].idxmax(axis=1)\n",
    "print(\"\\nFirst few rows of metadata:\")\n",
    "print(metadata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class Distribution:\n",
      "MEL      1113.0\n",
      "NV       6705.0\n",
      "BCC       514.0\n",
      "AKIEC     327.0\n",
      "BKL      1099.0\n",
      "DF        115.0\n",
      "VASC      142.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = metadata[classes].sum()\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAHWCAYAAACBjZMqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABbkklEQVR4nO3dd1xW9f//8ecFCijTCZKKe2BuS8mdKCo2tdzbbGCuclBmZqVmmavUhoqVZupHy1EqrlzkKtRMTXOWgqUC4gCF8/ujL+fnFWhcxpHh4367ndut6/1+X+/rdby4rnhyznkfm2EYhgAAAAAAWcopuwsAAAAAgLyIsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBSDPKFOmjHr16pXdZfxnY8aMkc1muyuv1axZMzVr1sx8vGnTJtlsNi1ZsuSuvH6vXr1UpkyZu/JaNztx4oRsNpsiIiLu+msDAO4dhC0AOd5vv/2mZ599VuXKlZObm5u8vLzUsGFDTZ06VVevXs3u8m4rIiJCNpvN3Nzc3OTv76+QkBBNmzZNly5dypLXOXPmjMaMGaPo6OgsmS8r5eTaslKzZs10//33Z9iXFu7ee++9DPu//fZb2Ww2+fv7KzU1NcMxZcqUkc1mU3BwcIb9n3zyiflztnv3brP97NmzGjlypJo3by5PT0/ZbDZt2rTplvuxfft2NWrUSAULFpSfn58GDhyoxMTEdOOSkpI0YsQI+fv7q0CBAqpfv74iIyPv2pz/1KtXL7vPmoeHh8qVK6cOHTrof//73y3/XTNjwYIFmjJlyh0/PytduXJFY8aMue17CCDnIGwByNFWrVql6tWra9GiRXrkkUc0ffp0jR8/XqVLl9awYcM0aNCg7C4xU8aOHavPP/9cM2fO1IsvvihJGjx4sKpXr659+/bZjR01apTDIfLMmTN64403HA40a9eu1dq1ax16jqNuV9snn3yiw4cPW/r6GQkICNDVq1fVvXv3u/7aGZk/f77KlCmjs2fPasOGDbcc5+bmpo0bNyomJibDOdzc3NK1Hz58WO+8847++OMPVa9e/bZ1REdHq0WLFrpy5Yref/999evXTx9//LGeeuqpdGN79eql999/X127dtXUqVPl7Oystm3bauvWrZbPeSuurq76/PPP9fnnn2vy5Mnq0qWLjhw5og4dOqhFixZKSEjI1Dz/lNPC1htvvEHYAnILAwByqGPHjhkeHh5GlSpVjDNnzqTrP3LkiDFlyhTzcUBAgNGzZ8+7WOG/mzt3riHJ2LVrV7q+9evXGwUKFDACAgKMK1eu/KfX2bVrlyHJmDt3bqbGX758OcP2jRs3GpKMxYsX/6d6/kttuVXTpk2NatWqZdh3/PhxQ5Lx7rvvputLTEw03N3djWnTphm1a9c2evXqleEcAQEBRosWLQwvLy+7n3vDMIzTp08bTk5ORvv27dP9vCUkJBjnz583DMMwFi9ebEgyNm7cmOFrtGnTxihRooQRHx9vtn3yySeGJGPNmjVm244dO9Ltz9WrV43y5csbQUFBls+ZkZ49exru7u4Z9o0fP96QZDz99NP/Ok9GQkNDjYCAgDt6blb7888/DUnG66+/nt2lAMgEjmwByLEmTpyoxMREzZ49WyVKlEjXX6FChdse2bpw4YJefvllVa9eXR4eHvLy8lKbNm20d+/edGOnT5+uatWqqWDBgipUqJDq1aunBQsWmP2XLl3S4MGDVaZMGbm6uqp48eJq2bKlfvzxxzvev4cfflivvfaaTp48qS+++MJsz+iarcjISDVq1Eg+Pj7y8PBQ5cqV9corr0j6+zqrBx54QJLUu3dv8zSqtOuR0k5v27Nnj5o0aaKCBQuaz/3nNVtpUlJS9Morr8jPz0/u7u569NFHdfr0absxt7pG7uY5/622jK7Zunz5sl566SWVKlVKrq6uqly5st577z0ZhmE3zmazacCAAfr66691//33y9XVVdWqVdPq1asz/ge/SUbXbPXq1UseHh76448/9Pjjj8vDw0PFihXTyy+/rJSUlH+d804tW7ZMV69e1VNPPaVOnTpp6dKlunbtWoZj3dzc9OSTT9r9bErSl19+qUKFCikkJCTdczw9PVW4cOF/rSMhIUGRkZHq1q2bvLy8zPYePXrIw8NDixYtMtuWLFkiZ2dn9e/f3662vn37KioqyvxZsWLOOzFy5Ei1atVKixcv1q+//mq2f/PNNwoNDZW/v79cXV1Vvnx5vfnmm3bvd7NmzbRq1SqdPHnS/PlN+5lNTk7W6NGjVbduXXl7e8vd3V2NGzfWxo0b09WwcOFC1a1bV56envLy8lL16tU1depUuzFxcXEaPHiw+bNfoUIFvfPOO+YpkCdOnFCxYsUkSW+88YZZz5gxY+743waAtfJldwEAcCsrVqxQuXLl9NBDD93R848dO6avv/5aTz31lMqWLavY2Fh99NFHatq0qX755Rf5+/tL+vtUtoEDB6pDhw4aNGiQrl27pn379mnHjh3q0qWLJOm5557TkiVLNGDAAAUGBur8+fPaunWrDh48qDp16tzxPnbv3l2vvPKK1q5dq2eeeSbDMQcOHFC7du1Uo0YNjR07Vq6urjp69Ki2bdsmSapatarGjh2r0aNHq3///mrcuLEk2f27nT9/Xm3atFGnTp3UrVs3+fr63raut99+WzabTSNGjNC5c+c0ZcoUBQcHKzo6WgUKFMj0/mWmtpsZhqFHH31UGzduVN++fVWrVi2tWbNGw4YN0x9//KHJkyfbjd+6dauWLl2qF154QZ6enpo2bZrat2+vU6dOqUiRIpmuM01KSopCQkJUv359vffee1q3bp0mTZqk8uXL6/nnn8/U8//666907RcvXrzlc+bPn6/mzZvLz89PnTp10siRI7VixYoMT7OTpC5duqhVq1b67bffVL58eUl/n+bWoUMH5c+fP5N7mt7+/ft148YN1atXz67dxcVFtWrV0k8//WS2/fTTT6pUqZJdgJKkBx98UNLfpw6WKlXKkjnvVPfu3bV27VpFRkaqUqVKkv6+ptLDw0NDhw6Vh4eHNmzYoNGjRyshIUHvvvuuJOnVV19VfHy8fv/9d/Pnz8PDQ9LfYfLTTz9V586d9cwzz+jSpUuaPXu2QkJCtHPnTtWqVUvS338s6dy5s1q0aKF33nlHknTw4EFt27bN/IPRlStX1LRpU/3xxx969tlnVbp0aW3fvl3h4eE6e/aspkyZomLFimnmzJl6/vnn9cQTT+jJJ5+UJNWoUeOO/10AWCy7D60BQEbi4+MNScZjjz2W6ef88zTCa9euGSkpKXZjjh8/bri6uhpjx4412x577LFbnv6Vxtvb2wgLC8t0LWludxrhzXPXrl3bfPz6668bN389T5482ZBk/Pnnn7ec43an6jVt2tSQZMyaNSvDvqZNm5qP004jvO+++4yEhASzfdGiRYYkY+rUqWbbrU7b/Oect6utZ8+edqdnff3114Yk46233rIb16FDB8NmsxlHjx412yQZLi4udm179+41JBnTp09P91o3Szut7+aaevbsaUiy+9kwDMOoXbu2Ubdu3dvOZxj//9/5dts/TyOMjY018uXLZ3zyySdm20MPPZThz31AQIARGhpq3Lhxw/Dz8zPefPNNwzAM45dffjEkGd9///2//rzd7jTCtL7Nmzen63vqqacMPz8/83G1atWMhx9+ON24AwcO2P2sWTHnrdzuNELDMIyffvrJkGQMGTLEbMvo9N1nn33WKFiwoHHt2jWz7VanEd64ccNISkqya7t48aLh6+tr9OnTx2wbNGiQ4eXlZdy4ceOW9b355puGu7u78euvv9q1jxw50nB2djZOnTplGAanEQK5DacRAsiR0i5k9/T0vOM5XF1d5eT099dcSkqKzp8/b56Cd/Ppfz4+Pvr999+1a9euW87l4+OjHTt26MyZM3dcz614eHjcdlVCHx8fSX+f8nSnK6q5urqqd+/emR7fo0cPu3/7Dh06qESJEvr222/v6PUz69tvv5Wzs7MGDhxo1/7SSy/JMAx99913du3BwcHm0R3p77/we3l56dixY3dcw3PPPWf3uHHjxpmer0yZMoqMjEy33Xya6M0WLlwoJycntW/f3mzr3Lmzvvvuu1seDXN2dtbTTz+tL7/8UtLfR8ZKlSplHjW8U2mLsri6uqbrc3Nzs1u05erVq7ccd/NcVsx5p9KORt38Wbv5KO2lS5f0119/qXHjxrpy5YoOHTr0r3M6OzvLxcVFkpSamqoLFy6YR/L++R1z+fLl266suHjxYjVu3FiFChXSX3/9ZW7BwcFKSUnR5s2bHd5nANmPsAUgR0o7lei/LI2empqqyZMnq2LFinJ1dVXRokVVrFgx7du3T/Hx8ea4ESNGyMPDQw8++KAqVqyosLAw8xS9NBMnTtTPP/+sUqVK6cEHH9SYMWP+0y/0N0tMTLxtqOzYsaMaNmyofv36ydfXV506ddKiRYscCl733Xef+UthZlSsWNHusc1mU4UKFXTixIlMz3EnTp48KX9//3T/HlWrVjX7b1a6dOl0cxQqVOi2p+3djpubm3lNzJ3M5+7uruDg4HRbw4YNMxz/xRdf6MEHH9T58+d19OhRHT16VLVr11ZycrIWL158y9fp0qWLfvnlF+3du1cLFixQp06d/vO92dKCR1JSUrq+a9eu2QWTAgUK3HLczXNZMeedSltq/uafrQMHDuiJJ56Qt7e3vLy8VKxYMXXr1k2S7L4jbmfevHmqUaOG3NzcVKRIERUrVkyrVq2ye/4LL7ygSpUqqU2bNipZsqT69OmT7trCI0eOaPXq1SpWrJjdlrbU/7lz5/7T/gPIHoQtADmSl5eX/P399fPPP9/xHOPGjdPQoUPVpEkTffHFF1qzZo0iIyNVrVo1u6BStWpVHT58WAsXLlSjRo30v//9T40aNdLrr79ujnn66ad17NgxTZ8+Xf7+/nr33XdVrVq1dEdaHPX7778rPj5eFSpUuOWYAgUKaPPmzVq3bp26d++uffv2qWPHjmrZsmWmF274r7+oZuRWv9xbuZjEPzk7O2fYbvxjMY3/Op8Vjhw5ol27dmnr1q2qWLGiuTVq1EjS30esbqV+/foqX768Bg8erOPHj5vXFv4XaYvQnD17Nl3f2bNnzWsc08beapwkc6wVc96ptO+StM9aXFycmjZtqr1792rs2LFasWKFIiMjzWuqMvPHjC+++EK9evVS+fLlNXv2bK1evVqRkZF6+OGH7Z5fvHhxRUdHa/ny5eY1iW3atFHPnj3NMampqWrZsmWGR0YjIyPtjn4CyD1YIANAjtWuXTt9/PHHioqKUlBQkMPPX7JkiZo3b67Zs2fbtcfFxalo0aJ2be7u7urYsaM6duyo5ORkPfnkk3r77bcVHh5unsZUokQJvfDCC3rhhRd07tw51alTR2+//bbatGlzx/v4+eefS1KGq8jdzMnJSS1atFCLFi30/vvva9y4cXr11Ve1ceNGBQcH/+ejGv905MgRu8eGYejo0aN2F+IXKlRIcXFx6Z578uRJlStXznzsSG0BAQFat26dLl26ZHcEIu2UroCAgEzPldPNnz9f+fPn1+eff54u5G3dulXTpk3TqVOnMjx6J/19uuFbb72lqlWrmgsx/Bf333+/8uXLp927d+vpp58225OTkxUdHW3XVqtWLW3cuFEJCQl2C1rs2LHD7Ldqzjv1+eefy2azqWXLlpL+Xinz/PnzWrp0qZo0aWKOO378eLrn3upneMmSJSpXrpyWLl1qN+bmP9SkcXFx0SOPPKJHHnlEqampeuGFF/TRRx/ptddeU4UKFVS+fHklJibe8qbV/1YLgJyJI1sAcqzhw4fL3d1d/fr1U2xsbLr+3377Ld3SyTdzdnZOd4Rj8eLF+uOPP+zazp8/b/fYxcVFgYGBMgxD169fV0pKSrpTiooXLy5/f/8MT3vKrA0bNujNN99U2bJl1bVr11uOu3DhQrq2tF88017f3d1dkjIMP3fis88+szuFc8mSJTp79qxdsCxfvrx++OEHJScnm20rV65Mt0S3I7W1bdtWKSkp+uCDD+zaJ0+eLJvN9p+CbU4zf/58NW7cWB07dlSHDh3stmHDhkmSeV1WRvr166fXX39dkyZNypJ6vL29FRwcrC+++MLuvf/888+VmJhotzpihw4dlJKSoo8//thsS0pK0ty5c1W/fn1z1UAr5rwTEyZM0Nq1a9WxY0fzFNm0gHvzd0RycrJmzJiR7vnu7u4ZnlaY0Rw7duxQVFSU3bh/fsc4OTmZf7hI+ww//fTTioqK0po1a9K9TlxcnG7cuCFJKliwoNkGIOfjyBaAHKt8+fJasGCBOnbsqKpVq6pHjx66//77lZycrO3bt2vx4sUZ3ucpTbt27TR27Fj17t1bDz30kPbv36/58+fbHXWRpFatWsnPz08NGzaUr6+vDh48qA8++EChoaHy9PRUXFycSpYsqQ4dOqhmzZry8PDQunXrtGvXrkz/ovvdd9/p0KFDunHjhmJjY7VhwwZFRkYqICBAy5cvN4+eZWTs2LHavHmzQkNDFRAQoHPnzmnGjBkqWbKkecpZ+fLl5ePjo1mzZsnT01Pu7u6qX7++ypYtm6n6/qlw4cJq1KiRevfurdjYWE2ZMkUVKlSwW56+X79+WrJkiVq3bq2nn35av/32m7744gu7BSscre2RRx5R8+bN9eqrr+rEiROqWbOm1q5dq2+++UaDBw9ON3dutWPHDh09elQDBgzIsP++++5TnTp1NH/+fI0YMSLDMQEBAZm+v9Jbb70l6e9rlKS/w87WrVslSaNGjTLHvf3223rooYfUtGlT9e/fX7///rsmTZqkVq1aqXXr1ua4+vXr66mnnlJ4eLjOnTunChUqaN68eTpx4kS6I8lWzHkrN27cMBcjuXbtmk6ePKnly5dr3759at68uV2Qe+ihh1SoUCH17NlTAwcOlM1m0+eff57hKah169bVV199paFDh+qBBx6Qh4eHHnnkEbVr105Lly7VE088odDQUB0/flyzZs1SYGCgeY2Y9Pdn5cKFC3r44YdVsmRJnTx5UtOnT1etWrXM6xGHDRum5cuXq127durVq5fq1q2ry5cva//+/VqyZIlOnDihokWLqkCBAgoMDNRXX32lSpUqqXDhwrr//vt1//33Z+rfCMBdln0LIQJA5vz666/GM888Y5QpU8ZwcXExPD09jYYNGxrTp0+3W545o6XfX3rpJaNEiRJGgQIFjIYNGxpRUVHplib/6KOPjCZNmhhFihQxXF1djfLlyxvDhg0z4uPjDcMwjKSkJGPYsGFGzZo1DU9PT8Pd3d2oWbOmMWPGjH+tPW0p7rTNxcXF8PPzM1q2bGlMnTrVbnn1NP9c+n39+vXGY489Zvj7+xsuLi6Gv7+/0blz53RLRH/zzTdGYGCgkS9fPrtlzZs2bXrLpe1vtfT7l19+aYSHhxvFixc3ChQoYISGhhonT55M9/xJkyYZ9913n+Hq6mo0bNjQ2L17d7o5b1fbP5d+NwzDuHTpkjFkyBDD39/fyJ8/v1GxYkXj3XffNVJTU+3GScpwOf5bLUl/s1st/Z7R0uH/fD9u5Xb/zmmvl7b0+4svvmhIMn777bdbzjdmzBhDkrF3717DMP7/0u+3c6ul36VbL0f/T1u2bDEeeughw83NzShWrJgRFhaW4c/p1atXjZdfftnw8/MzXF1djQceeMBYvXp1hnVZMec/pS3dn7YVLFjQKFOmjNG+fXtjyZIl6W4DYRiGsW3bNqNBgwZGgQIFDH9/f2P48OHGmjVr0i2Pn5iYaHTp0sXw8fExJJk/s6mpqca4ceOMgIAAw9XV1ahdu7axcuXKdD/XS5YsMVq1amUUL17ccHFxMUqXLm08++yzxtmzZ+3quXTpkhEeHm5UqFDBcHFxMYoWLWo89NBDxnvvvWckJyeb47Zv327UrVvXcHFxYRl4IIezGcYdXkUMAAAAALglrtkCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALZGvYKlOmjGw2W7otLCxM0t/3yAgLC1ORIkXk4eGh9u3bp7ux6alTpxQaGqqCBQuqePHiGjZsmHnjvzSbNm1SnTp15OrqqgoVKigiIuJu7SIAAACAe1S23tR4165dSklJMR///PPPatmypXlH+SFDhmjVqlVavHixvL29NWDAAD355JPatm2bJCklJUWhoaHy8/PT9u3bdfbsWfXo0UP58+fXuHHjJEnHjx9XaGionnvuOc2fP1/r169Xv379VKJECYWEhGSqztTUVJ05c0aenp6y2WxZ/K8AAAAAILcwDEOXLl2Sv7+/nJz+5dhVNt/ny86gQYOM8uXLG6mpqUZcXJyRP39+Y/HixWb/wYMHDUlGVFSUYRiG8e233xpOTk5GTEyMOWbmzJmGl5eXkZSUZBiGYQwfPjzdTSY7duxohISEZLqu06dP3/aGkGxsbGxsbGxsbGxs99Z2+vTpf80R2Xpk62bJycn64osvNHToUNlsNu3Zs0fXr19XcHCwOaZKlSoqXbq0oqKi1KBBA0VFRal69ery9fU1x4SEhOj555/XgQMHVLt2bUVFRdnNkTZm8ODBt6wlKSlJSUlJ5mPj/+77fPr0aXl5eWXRHgMAAADIbRISElSqVCl5enr+69gcE7a+/vprxcXFqVevXpKkmJgYubi4yMfHx26cr6+vYmJizDE3B620/rS+241JSEjQ1atXVaBAgXS1jB8/Xm+88Ua6di8vL8IWAAAAgExdXpRjViOcPXu22rRpI39//+wuReHh4YqPjze306dPZ3dJAAAAAHKZHHFk6+TJk1q3bp2WLl1qtvn5+Sk5OVlxcXF2R7diY2Pl5+dnjtm5c6fdXGmrFd485p8rGMbGxsrLyyvDo1qS5OrqKldX1/+8XwAAAADuXTniyNbcuXNVvHhxhYaGmm1169ZV/vz5tX79erPt8OHDOnXqlIKCgiRJQUFB2r9/v86dO2eOiYyMlJeXlwIDA80xN8+RNiZtDgAAAACwQraHrdTUVM2dO1c9e/ZUvnz//0Cbt7e3+vbtq6FDh2rjxo3as2ePevfuraCgIDVo0ECS1KpVKwUGBqp79+7au3ev1qxZo1GjRiksLMw8MvXcc8/p2LFjGj58uA4dOqQZM2Zo0aJFGjJkSLbsLwAAAIB7Q7afRrhu3TqdOnVKffr0Sdc3efJkOTk5qX379kpKSlJISIhmzJhh9js7O2vlypV6/vnnFRQUJHd3d/Xs2VNjx441x5QtW1arVq3SkCFDNHXqVJUsWVKffvpppu+xBQAAAAB3wmakrWuOW0pISJC3t7fi4+NZjRAAAAC4hzmSDbL9NEIAAAAAyIsIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABfJldwFAXlNm5KrsLiHPODEhNLtLAAAAuGMc2QIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwALZHrb++OMPdevWTUWKFFGBAgVUvXp17d692+w3DEOjR49WiRIlVKBAAQUHB+vIkSN2c1y4cEFdu3aVl5eXfHx81LdvXyUmJtqN2bdvnxo3biw3NzeVKlVKEydOvCv7BwAAAODelK1h6+LFi2rYsKHy58+v7777Tr/88osmTZqkQoUKmWMmTpyoadOmadasWdqxY4fc3d0VEhKia9eumWO6du2qAwcOKDIyUitXrtTmzZvVv39/sz8hIUGtWrVSQECA9uzZo3fffVdjxozRxx9/fFf3FwAAAMC9w2YYhpFdLz5y5Eht27ZNW7ZsybDfMAz5+/vrpZde0ssvvyxJio+Pl6+vryIiItSpUycdPHhQgYGB2rVrl+rVqydJWr16tdq2bavff/9d/v7+mjlzpl599VXFxMTIxcXFfO2vv/5ahw4d+tc6ExIS5O3trfj4eHl5eWXR3iOvKjNyVXaXkGecmBCa3SUAAADYcSQbZOuRreXLl6tevXp66qmnVLx4cdWuXVuffPKJ2X/8+HHFxMQoODjYbPP29lb9+vUVFRUlSYqKipKPj48ZtCQpODhYTk5O2rFjhzmmSZMmZtCSpJCQEB0+fFgXL15MV1dSUpISEhLsNgAAAABwRLaGrWPHjmnmzJmqWLGi1qxZo+eff14DBw7UvHnzJEkxMTGSJF9fX7vn+fr6mn0xMTEqXry4XX++fPlUuHBhuzEZzXHza9xs/Pjx8vb2NrdSpUplwd4CAAAAuJdka9hKTU1VnTp1NG7cONWuXVv9+/fXM888o1mzZmVnWQoPD1d8fLy5nT59OlvrAQAAAJD7ZGvYKlGihAIDA+3aqlatqlOnTkmS/Pz8JEmxsbF2Y2JjY80+Pz8/nTt3zq7/xo0bunDhgt2YjOa4+TVu5urqKi8vL7sNAAAAAByRrWGrYcOGOnz4sF3br7/+qoCAAElS2bJl5efnp/Xr15v9CQkJ2rFjh4KCgiRJQUFBiouL0549e8wxGzZsUGpqqurXr2+O2bx5s65fv26OiYyMVOXKle1WPgQAAACArJKtYWvIkCH64YcfNG7cOB09elQLFizQxx9/rLCwMEmSzWbT4MGD9dZbb2n58uXav3+/evToIX9/fz3++OOS/j4S1rp1az3zzDPauXOntm3bpgEDBqhTp07y9/eXJHXp0kUuLi7q27evDhw4oK+++kpTp07V0KFDs2vXAQAAAORx+bLzxR944AEtW7ZM4eHhGjt2rMqWLaspU6aoa9eu5pjhw4fr8uXL6t+/v+Li4tSoUSOtXr1abm5u5pj58+drwIABatGihZycnNS+fXtNmzbN7Pf29tbatWsVFhamunXrqmjRoho9erTdvbgAAAAAICtl6322cgvuswVHcJ+trMN9tgAAQE6Ta+6zBQAAAAB5FWELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAtka9gaM2aMbDab3ValShWz/9q1awoLC1ORIkXk4eGh9u3bKzY21m6OU6dOKTQ0VAULFlTx4sU1bNgw3bhxw27Mpk2bVKdOHbm6uqpChQqKiIi4G7sHAAAA4B6W7Ue2qlWrprNnz5rb1q1bzb4hQ4ZoxYoVWrx4sb7//nudOXNGTz75pNmfkpKi0NBQJScna/v27Zo3b54iIiI0evRoc8zx48cVGhqq5s2bKzo6WoMHD1a/fv20Zs2au7qfAAAAAO4t+bK9gHz55Ofnl649Pj5es2fP1oIFC/Twww9LkubOnauqVavqhx9+UIMGDbR27Vr98ssvWrdunXx9fVWrVi29+eabGjFihMaMGSMXFxfNmjVLZcuW1aRJkyRJVatW1datWzV58mSFhITc1X0FAAAAcO/I9iNbR44ckb+/v8qVK6euXbvq1KlTkqQ9e/bo+vXrCg4ONsdWqVJFpUuXVlRUlCQpKipK1atXl6+vrzkmJCRECQkJOnDggDnm5jnSxqTNkZGkpCQlJCTYbQAAAADgiGwNW/Xr11dERIRWr16tmTNn6vjx42rcuLEuXbqkmJgYubi4yMfHx+45vr6+iomJkSTFxMTYBa20/rS+241JSEjQ1atXM6xr/Pjx8vb2NrdSpUplxe4CAAAAuIdk62mEbdq0Mf+7Ro0aql+/vgICArRo0SIVKFAg2+oKDw/X0KFDzccJCQkELgAAAAAOyfbTCG/m4+OjSpUq6ejRo/Lz81NycrLi4uLsxsTGxprXePn5+aVbnTDt8b+N8fLyumWgc3V1lZeXl90GAAAAAI7IUWErMTFRv/32m0qUKKG6desqf/78Wr9+vdl/+PBhnTp1SkFBQZKkoKAg7d+/X+fOnTPHREZGysvLS4GBgeaYm+dIG5M2BwAAAABYIVvD1ssvv6zvv/9eJ06c0Pbt2/XEE0/I2dlZnTt3lre3t/r27auhQ4dq48aN2rNnj3r37q2goCA1aNBAktSqVSsFBgaqe/fu2rt3r9asWaNRo0YpLCxMrq6ukqTnnntOx44d0/Dhw3Xo0CHNmDFDixYt0pAhQ7Jz1wEAAADkcdl6zdbvv/+uzp076/z58ypWrJgaNWqkH374QcWKFZMkTZ48WU5OTmrfvr2SkpIUEhKiGTNmmM93dnbWypUr9fzzzysoKEju7u7q2bOnxo4da44pW7asVq1apSFDhmjq1KkqWbKkPv30U5Z9BwAAAGApm2EYRnYXkdMlJCTI29tb8fHxXL+Ff1Vm5KrsLiHPODEhNLtLAAAAsONINshR12wBAAAAQF5B2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAg6HrdOnT+v33383H+/cuVODBw/Wxx9/nKWFAQAAAEBu5nDY6tKlizZu3ChJiomJUcuWLbVz5069+uqrGjt2bJYXCAAAAAC5kcNh6+eff9aDDz4oSVq0aJHuv/9+bd++XfPnz1dERERW1wcAAAAAuZLDYev69etydXWVJK1bt06PPvqoJKlKlSo6e/Zs1lYHAAAAALmUw2GrWrVqmjVrlrZs2aLIyEi1bt1aknTmzBkVKVIkywsEAAAAgNzI4bD1zjvv6KOPPlKzZs3UuXNn1axZU5K0fPly8/RCAAAAALjX5XP0Cc2aNdNff/2lhIQEFSpUyGzv37+/ChYsmKXFAQAAAEBudUf32TIMQ3v27NFHH32kS5cuSZJcXFwIWwAAAADwfxw+snXy5Em1bt1ap06dUlJSklq2bClPT0+98847SkpK0qxZs6yoEwAAAAByFYePbA0aNEj16tXTxYsXVaBAAbP9iSee0Pr167O0OAAAAADIrRw+srVlyxZt375dLi4udu1lypTRH3/8kWWFAQAAAEBu5vCRrdTUVKWkpKRr//333+Xp6ZklRQEAAABAbudw2GrVqpWmTJliPrbZbEpMTNTrr7+utm3bZmVtAAAAAJBrOXwa4aRJkxQSEqLAwEBdu3ZNXbp00ZEjR1S0aFF9+eWXVtQIAAAAALmOw2GrZMmS2rt3rxYuXKh9+/YpMTFRffv2VdeuXe0WzAAAAACAe5nDYUuS8uXLp27dumV1LQAAAACQZ2QqbC1fvjzTEz766KN3XAwAAAAA5BWZCluPP/54piaz2WwZrlQIAAAAAPeaTIWt1NRUq+sAAAAAgDzF4aXfAQAAAAD/7o7C1vr169WuXTuVL19e5cuXV7t27bRu3bqsrg0AAAAAci2Hw9aMGTPUunVreXp6atCgQRo0aJC8vLzUtm1bffjhh1bUCAAAAAC5jsNLv48bN06TJ0/WgAEDzLaBAweqYcOGGjdunMLCwrK0QAAAAADIjRw+shUXF6fWrVuna2/VqpXi4+OzpCgAAAAAyO0cDluPPvqoli1blq79m2++Ubt27bKkKAAAAADI7Rw+jTAwMFBvv/22Nm3apKCgIEnSDz/8oG3btumll17StGnTzLEDBw7MukoBAAAAIBexGYZhOPKEsmXLZm5im03Hjh27o6JymoSEBHl7eys+Pl5eXl7ZXQ5yuDIjV2V3CXnGiQmh2V0CAACAHUeygcNHto4fP37HhQEAAADAvYKbGgMAAACABRw+smUYhpYsWaKNGzfq3LlzSk1NtetfunRplhUHAAAAALmVw2Fr8ODB+uijj9S8eXP5+vrKZrNZURcAAAAA5GoOh63PP/9cS5cuVdu2ba2oBwAAAADyBIev2fL29la5cuWsqAUAAAAA8gyHw9aYMWP0xhtv6OrVq1bUAwAAAAB5gsOnET799NP68ssvVbx4cZUpU0b58+e36//xxx+zrDgAAAAAyK0cDls9e/bUnj171K1bNxbIAAAAAIBbcDhsrVq1SmvWrFGjRo2sqAcAAAAA8gSHr9kqVaqUvLy8sryQCRMmyGazafDgwWbbtWvXFBYWpiJFisjDw0Pt27dXbGys3fNOnTql0NBQFSxYUMWLF9ewYcN048YNuzGbNm1SnTp15OrqqgoVKigiIiLL6wcAAACAmzkctiZNmqThw4frxIkTWVbErl279NFHH6lGjRp27UOGDNGKFSu0ePFiff/99zpz5oyefPJJsz8lJUWhoaFKTk7W9u3bNW/ePEVERGj06NHmmOPHjys0NFTNmzdXdHS0Bg8erH79+mnNmjVZVj8AAAAA/JPNMAzDkScUKlRIV65c0Y0bN1SwYMF0C2RcuHDBoQISExNVp04dzZgxQ2+99ZZq1aqlKVOmKD4+XsWKFdOCBQvUoUMHSdKhQ4dUtWpVRUVFqUGDBvruu+/Url07nTlzRr6+vpKkWbNmacSIEfrzzz/l4uKiESNGaNWqVfr555/N1+zUqZPi4uK0evXqTNWYkJAgb29vxcfHW3JUD3lLmZGrsruEPOPEhNDsLgEAAMCOI9nA4Wu2pkyZcqd1ZSgsLEyhoaEKDg7WW2+9Zbbv2bNH169fV3BwsNlWpUoVlS5d2gxbUVFRql69uhm0JCkkJETPP/+8Dhw4oNq1aysqKspujrQxN5+u+E9JSUlKSkoyHyckJGTBngIAAAC4l9zRaoRZZeHChfrxxx+1a9eudH0xMTFycXGRj4+PXbuvr69iYmLMMTcHrbT+tL7bjUlISNDVq1dVoECBdK89fvx4vfHGG3e8XwAAAADg8DVbN7t27ZoSEhLstsw6ffq0Bg0apPnz58vNze2/lJHlwsPDFR8fb26nT5/O7pIAAAAA5DIOh63Lly9rwIABKl68uNzd3VWoUCG7LbP27Nmjc+fOqU6dOsqXL5/y5cun77//XtOmTVO+fPnk6+ur5ORkxcXF2T0vNjZWfn5+kiQ/P790qxOmPf63MV5eXhke1ZIkV1dXeXl52W0AAAAA4AiHw9bw4cO1YcMGzZw5U66urvr000/1xhtvyN/fX5999lmm52nRooX279+v6Ohoc6tXr566du1q/nf+/Pm1fv168zmHDx/WqVOnFBQUJEkKCgrS/v37de7cOXNMZGSkvLy8FBgYaI65eY60MWlzAAAAAIAVHL5ma8WKFfrss8/UrFkz9e7dW40bN1aFChUUEBCg+fPnq2vXrpmax9PTU/fff79dm7u7u4oUKWK29+3bV0OHDlXhwoXl5eWlF198UUFBQWrQoIEkqVWrVgoMDFT37t01ceJExcTEaNSoUQoLC5Orq6sk6bnnntMHH3yg4cOHq0+fPtqwYYMWLVqkVatYMQ4AAACAdRw+snXhwgWVK1dOkuTl5WUu9d6oUSNt3rw5S4ubPHmy2rVrp/bt26tJkyby8/PT0qVLzX5nZ2etXLlSzs7OCgoKUrdu3dSjRw+NHTvWHFO2bFmtWrVKkZGRqlmzpiZNmqRPP/1UISEhWVorAAAAANzM4SNb5cqV0/Hjx1W6dGlVqVJFixYt0oMPPqgVK1akWznQUZs2bbJ77Obmpg8//FAffvjhLZ8TEBCgb7/99rbzNmvWTD/99NN/qg0AAAAAHOHwka3evXtr7969kqSRI0fqww8/lJubm4YMGaJhw4ZleYEAAAAAkBs5fGRryJAh5n8HBwfr4MGD+vHHH1WhQgXVqFEjS4sDAAAAgNzK4bD1T2XKlFGZMmWyoBQAAAAAyDsyfRphVFSUVq5cadf22WefqWzZsipevLj69++vpKSkLC8QAAAAAHKjTIetsWPH6sCBA+bj/fv3q2/fvgoODtbIkSO1YsUKjR8/3pIiAQAAACC3yXTYio6OVosWLczHCxcuVP369fXJJ59o6NChmjZtmhYtWmRJkQAAAACQ22Q6bF28eFG+vr7m4++//15t2rQxHz/wwAM6ffp01lYHAAAAALlUpsOWr6+vjh8/LklKTk7Wjz/+qAYNGpj9ly5dUv78+bO+QgAAAADIhTIdttq2bauRI0dqy5YtCg8PV8GCBdW4cWOzf9++fSpfvrwlRQIAAABAbpPppd/ffPNNPfnkk2ratKk8PDw0b948ubi4mP1z5sxRq1atLCkSAAAAAHKbTIetokWLavPmzYqPj5eHh4ecnZ3t+hcvXiwPD48sLxAAAAAAciOHb2rs7e2dYXvhwoX/czEAAAAAkFdk+potAAAAAEDmEbYAAAAAwAKELQAAAACwQKbCVp06dXTx4kVJ0tixY3XlyhVLiwIAAACA3C5TYevgwYO6fPmyJOmNN95QYmKipUUBAAAAQG6XqdUIa9Wqpd69e6tRo0YyDEPvvffeLZd5Hz16dJYWCAAAAAC5UabCVkREhF5//XWtXLlSNptN3333nfLlS/9Um81G2AIAAAAAZTJsVa5cWQsXLpQkOTk5af369SpevLilhQEAAABAbubwTY1TU1OtqAMAAAAA8hSHw5Yk/fbbb5oyZYoOHjwoSQoMDNSgQYNUvnz5LC0OAAAAAHIrh++ztWbNGgUGBmrnzp2qUaOGatSooR07dqhatWqKjIy0okYAAAAAyHUcPrI1cuRIDRkyRBMmTEjXPmLECLVs2TLLigMAAACA3MrhI1sHDx5U375907X36dNHv/zyS5YUBQAAAAC5ncNhq1ixYoqOjk7XHh0dzQqFAAAAAPB/HD6N8JlnnlH//v117NgxPfTQQ5Kkbdu26Z133tHQoUOzvEAAAAAAyI0cDluvvfaaPD09NWnSJIWHh0uS/P39NWbMGA0cODDLCwQAAACA3MjhsGWz2TRkyBANGTJEly5dkiR5enpmeWEAAAAAkJvd0X220hCyAAAAACBjDi+QAQAAAAD4d4QtAAAAALAAYQsAAAAALOBQ2Lp+/bpatGihI0eOWFUPAAAAAOQJDoWt/Pnza9++fVbVAgAAAAB5hsOnEXbr1k2zZ8+2ohYAAAAAyDMcXvr9xo0bmjNnjtatW6e6devK3d3drv/999/PsuIAAAAAILdyOGz9/PPPqlOnjiTp119/teuz2WxZUxUAAAAA5HIOh62NGzdaUQcAAAAA5Cl3vPT70aNHtWbNGl29elWSZBhGlhUFAAAAALmdw2Hr/PnzatGihSpVqqS2bdvq7NmzkqS+ffvqpZdeyvICAQAAACA3cjhsDRkyRPnz59epU6dUsGBBs71jx45avXp1lhYHAAAAALmVw9dsrV27VmvWrFHJkiXt2itWrKiTJ09mWWEAAAAAkJs5fGTr8uXLdke00ly4cEGurq5ZUhQAAAAA5HYOh63GjRvrs88+Mx/bbDalpqZq4sSJat68uUNzzZw5UzVq1JCXl5e8vLwUFBSk7777zuy/du2awsLCVKRIEXl4eKh9+/aKjY21m+PUqVMKDQ1VwYIFVbx4cQ0bNkw3btywG7Np0ybVqVNHrq6uqlChgiIiIhzdbQAAAABwiMOnEU6cOFEtWrTQ7t27lZycrOHDh+vAgQO6cOGCtm3b5tBcJUuW1IQJE1SxYkUZhqF58+bpscce008//aRq1appyJAhWrVqlRYvXixvb28NGDBATz75pPk6KSkpCg0NlZ+fn7Zv366zZ8+qR48eyp8/v8aNGydJOn78uEJDQ/Xcc89p/vz5Wr9+vfr166cSJUooJCTE0d0HAAAAgEyxGXewZnt8fLw++OAD7d27V4mJiapTp47CwsJUokSJ/1xQ4cKF9e6776pDhw4qVqyYFixYoA4dOkiSDh06pKpVqyoqKkoNGjTQd999p3bt2unMmTPy9fWVJM2aNUsjRozQn3/+KRcXF40YMUKrVq3Szz//bL5Gp06dFBcXl+kFPRISEuTt7a34+Hh5eXn9531E3lZm5KrsLiHPODEhNLtLAAAAsONINnD4yJYkeXt769VXX72j4m4lJSVFixcv1uXLlxUUFKQ9e/bo+vXrCg4ONsdUqVJFpUuXNsNWVFSUqlevbgYtSQoJCdHzzz+vAwcOqHbt2oqKirKbI23M4MGDb1lLUlKSkpKSzMcJCQlZt6MAAAAA7gl3FLYuXryo2bNn6+DBg5KkwMBA9e7dW4ULF3Z4rv379ysoKEjXrl2Th4eHli1bpsDAQEVHR8vFxUU+Pj524319fRUTEyNJiomJsQtaaf1pfbcbk5CQoKtXr6pAgQLpaho/frzeeOMNh/cFAAAAANI4vEDG5s2bVaZMGU2bNk0XL17UxYsXNW3aNJUtW1abN292uIDKlSsrOjpaO3bs0PPPP6+ePXvql19+cXierBQeHq74+HhzO336dLbWAwAAACD3cfjIVlhYmDp27KiZM2fK2dlZ0t+nAL7wwgsKCwvT/v37HZrPxcVFFSpUkCTVrVtXu3bt0tSpU9WxY0clJycrLi7O7uhWbGys/Pz8JEl+fn7auXOn3XxpqxXePOafKxjGxsbKy8srw6NakuTq6soy9gAAAAD+E4ePbB09elQvvfSSGbQkydnZWUOHDtXRo0f/c0GpqalKSkpS3bp1lT9/fq1fv97sO3z4sE6dOqWgoCBJUlBQkPbv369z586ZYyIjI+Xl5aXAwEBzzM1zpI1JmwMAAAAArODwka06dero4MGDqly5sl37wYMHVbNmTYfmCg8PV5s2bVS6dGldunRJCxYs0KZNm7RmzRp5e3urb9++Gjp0qAoXLiwvLy+9+OKLCgoKUoMGDSRJrVq1UmBgoLp3766JEycqJiZGo0aNUlhYmHlk6rnnntMHH3yg4cOHq0+fPtqwYYMWLVqkVatYMQ4AAACAdTIVtvbt22f+98CBAzVo0CAdPXrUDD0//PCDPvzwQ02YMMGhFz937px69Oihs2fPytvbWzVq1NCaNWvUsmVLSdLkyZPl5OSk9u3bKykpSSEhIZoxY4b5fGdnZ61cuVLPP/+8goKC5O7urp49e2rs2LHmmLJly2rVqlUaMmSIpk6dqpIlS+rTTz/lHlsAAAAALJWp+2w5OTnJZrPp34babDalpKRkWXE5BffZgiO4z1bW4T5bAAAgp8ny+2wdP348SwoDAAAAgHtFpsJWQECA1XUAAAAAQJ5yRzc1PnPmjLZu3apz584pNTXVrm/gwIFZUhgAAAAA5GYOh62IiAg9++yzcnFxUZEiRWSz2cw+m81G2AIAAAAA3UHYeu211zR69GiFh4fLycnh23QBAAAAwD3B4bR05coVderUiaAFAAAAALfhcGLq27evFi9ebEUtAAAAAJBnOHwa4fjx49WuXTutXr1a1atXV/78+e3633///SwrDgAAAAByqzsKW2vWrFHlypUlKd0CGQAAAACAOwhbkyZN0pw5c9SrVy8LygEAAACAvMHha7ZcXV3VsGFDK2oBAAAAgDzD4bA1aNAgTZ8+3YpaAAAAACDPcPg0wp07d2rDhg1auXKlqlWrlm6BjKVLl2ZZcQAAAACQWzkctnx8fPTkk09aUQsAAAAA5BkOh625c+daUQcAAAAA5CkOX7MFAAAAAPh3Dh/ZKlu27G3vp3Xs2LH/VBAAAAAA5AUOh63BgwfbPb5+/bp++uknrV69WsOGDcuqugAAAAAgV3M4bA0aNCjD9g8//FC7d+/+zwUBAAAAQF6QZddstWnTRv/73/+yajoAAAAAyNWyLGwtWbJEhQsXzqrpAAAAACBXc/g0wtq1a9stkGEYhmJiYvTnn39qxowZWVocAAAAAORWDoetxx9/3O6xk5OTihUrpmbNmqlKlSpZVRcAAAAA5GoOh63XX3/dijoAAAAAIE/hpsYAAAAAYIFMH9lycnK67c2MJclms+nGjRv/uSgAAAAAyO0yHbaWLVt2y76oqChNmzZNqampWVIUAAAAAOR2mQ5bjz32WLq2w4cPa+TIkVqxYoW6du2qsWPHZmlxAAAAAJBb3dE1W2fOnNEzzzyj6tWr68aNG4qOjta8efMUEBCQ1fUBAAAAQK7kUNiKj4/XiBEjVKFCBR04cEDr16/XihUrdP/991tVHwAAAADkSpk+jXDixIl655135Ofnpy+//DLD0woBAAAAAH+zGYZhZGagk5OTChQooODgYDk7O99y3NKlS7OsuJwiISFB3t7eio+Pl5eXV3aXgxyuzMhV2V1CnnFiQmh2lwAAAGDHkWyQ6SNbPXr0+Nel3wEAAAAAf8t02IqIiLCwDAAAAADIW+5oNUIAAAAAwO0RtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAAC2Rr2Bo/frweeOABeXp6qnjx4nr88cd1+PBhuzHXrl1TWFiYihQpIg8PD7Vv316xsbF2Y06dOqXQ0FAVLFhQxYsX17Bhw3Tjxg27MZs2bVKdOnXk6uqqChUqKCIiwurdAwAAAHAPy9aw9f333yssLEw//PCDIiMjdf36dbVq1UqXL182xwwZMkQrVqzQ4sWL9f333+vMmTN68sknzf6UlBSFhoYqOTlZ27dv17x58xQREaHRo0ebY44fP67Q0FA1b95c0dHRGjx4sPr166c1a9bc1f0FAAAAcO+wGYZhZHcRaf78808VL15c33//vZo0aaL4+HgVK1ZMCxYsUIcOHSRJhw4dUtWqVRUVFaUGDRrou+++U7t27XTmzBn5+vpKkmbNmqURI0bozz//lIuLi0aMGKFVq1bp559/Nl+rU6dOiouL0+rVq/+1roSEBHl7eys+Pl5eXl7W7DzyjDIjV2V3CXnGiQmh2V0CAACAHUeyQY66Zis+Pl6SVLhwYUnSnj17dP36dQUHB5tjqlSpotKlSysqKkqSFBUVperVq5tBS5JCQkKUkJCgAwcOmGNuniNtTNoc/5SUlKSEhAS7DQAAAAAckWPCVmpqqgYPHqyGDRvq/vvvlyTFxMTIxcVFPj4+dmN9fX0VExNjjrk5aKX1p/XdbkxCQoKuXr2arpbx48fL29vb3EqVKpUl+wgAAADg3pFjwlZYWJh+/vlnLVy4MLtLUXh4uOLj483t9OnT2V0SAAAAgFwmX3YXIEkDBgzQypUrtXnzZpUsWdJs9/PzU3JysuLi4uyObsXGxsrPz88cs3PnTrv50lYrvHnMP1cwjI2NlZeXlwoUKJCuHldXV7m6umbJvgEAAAC4N2XrkS3DMDRgwAAtW7ZMGzZsUNmyZe3669atq/z582v9+vVm2+HDh3Xq1CkFBQVJkoKCgrR//36dO3fOHBMZGSkvLy8FBgaaY26eI21M2hwAAAAAkNWy9chWWFiYFixYoG+++Uaenp7mNVbe3t4qUKCAvL291bdvXw0dOlSFCxeWl5eXXnzxRQUFBalBgwaSpFatWikwMFDdu3fXxIkTFRMTo1GjRiksLMw8OvXcc8/pgw8+0PDhw9WnTx9t2LBBixYt0qpVrBoHAAAAwBrZemRr5syZio+PV7NmzVSiRAlz++qrr8wxkydPVrt27dS+fXs1adJEfn5+Wrp0qdnv7OyslStXytnZWUFBQerWrZt69OihsWPHmmPKli2rVatWKTIyUjVr1tSkSZP06aefKiQk5K7uLwAAAIB7R466z1ZOxX224Ajus5V1uM8WAADIaXLtfbYAAAAAIK8gbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAXyZXcBuDNlRq7K7hLyjBMTQrO7BAAAAORBhC0AAPCv+CNf1uGPfMC9I1tPI9y8ebMeeeQR+fv7y2az6euvv7brNwxDo0ePVokSJVSgQAEFBwfryJEjdmMuXLigrl27ysvLSz4+Purbt68SExPtxuzbt0+NGzeWm5ubSpUqpYkTJ1q9awAAAADucdkati5fvqyaNWvqww8/zLB/4sSJmjZtmmbNmqUdO3bI3d1dISEhunbtmjmma9euOnDggCIjI7Vy5Upt3rxZ/fv3N/sTEhLUqlUrBQQEaM+ePXr33Xc1ZswYffzxx5bvHwAAAIB7V7aeRtimTRu1adMmwz7DMDRlyhSNGjVKjz32mCTps88+k6+vr77++mt16tRJBw8e1OrVq7Vr1y7Vq1dPkjR9+nS1bdtW7733nvz9/TV//nwlJydrzpw5cnFxUbVq1RQdHa3333/fLpQBAAAAQFbKsasRHj9+XDExMQoODjbbvL29Vb9+fUVFRUmSoqKi5OPjYwYtSQoODpaTk5N27NhhjmnSpIlcXFzMMSEhITp8+LAuXryY4WsnJSUpISHBbgMAAAAAR+TYsBUTEyNJ8vX1tWv39fU1+2JiYlS8eHG7/nz58qlw4cJ2YzKa4+bX+Kfx48fL29vb3EqVKvXfdwgAAADAPSXHhq3sFB4ervj4eHM7ffp0dpcEAAAAIJfJsWHLz89PkhQbG2vXHhsba/b5+fnp3Llzdv03btzQhQsX7MZkNMfNr/FPrq6u8vLystsAAAAAwBE5NmyVLVtWfn5+Wr9+vdmWkJCgHTt2KCgoSJIUFBSkuLg47dmzxxyzYcMGpaamqn79+uaYzZs36/r16+aYyMhIVa5cWYUKFbpLewMAAADgXpOtYSsxMVHR0dGKjo6W9PeiGNHR0Tp16pRsNpsGDx6st956S8uXL9f+/fvVo0cP+fv76/HHH5ckVa1aVa1bt9YzzzyjnTt3atu2bRowYIA6deokf39/SVKXLl3k4uKivn376sCBA/rqq680depUDR06NJv2GgAAAMC9IFuXft+9e7eaN29uPk4LQD179lRERISGDx+uy5cvq3///oqLi1OjRo20evVqubm5mc+ZP3++BgwYoBYtWsjJyUnt27fXtGnTzH5vb2+tXbtWYWFhqlu3rooWLarRo0ez7DsAAAAAS2Vr2GrWrJkMw7hlv81m09ixYzV27NhbjilcuLAWLFhw29epUaOGtmzZcsd1AgAAAICjcuw1WwAAAACQmxG2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALJAvuwsAgLupzMhV2V1CnnFiQmh2lwAAQI7GkS0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtgAAAADAAoQtAAAAALAAYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwQL7sLgAAAEkqM3JVdpeQZ5yYEJrdJQAAxJEtAAAAALAEYQsAAAAALEDYAgAAAAALELYAAAAAwAKELQAAAACwAGELAAAAACxA2AIAAAAACxC2AAAAAMAChC0AAAAAsEC+7C4AAAAAyKvKjFyV3SXkGScmhGZ3CQ4jbAEAAORy/EKfdXLjL/TIuTiNEAAAAAAsQNgCAAAAAAvcU2Hrww8/VJkyZeTm5qb69etr586d2V0SAAAAgDzqnglbX331lYYOHarXX39dP/74o2rWrKmQkBCdO3cuu0sDAAAAkAfdM2Hr/fff1zPPPKPevXsrMDBQs2bNUsGCBTVnzpzsLg0AAABAHnRPrEaYnJysPXv2KDw83GxzcnJScHCwoqKi0o1PSkpSUlKS+Tg+Pl6SlJCQYH2xmZSadCW7S8gzsvp95b3JOlZ85nh/sg6fnZyLz07OxvuTs/HdlnPllN/F0+owDONfx94TYeuvv/5SSkqKfH197dp9fX116NChdOPHjx+vN954I117qVKlLKsR2cd7SnZXgFvhvcnZeH9yLt6bnI33J2fj/cm5ctp7c+nSJXl7e992zD0RthwVHh6uoUOHmo9TU1N14cIFFSlSRDabLRsryz0SEhJUqlQpnT59Wl5eXtldDv6B9yfn4r3J2Xh/cjben5yL9yZn4/1xjGEYunTpkvz9/f917D0RtooWLSpnZ2fFxsbatcfGxsrPzy/deFdXV7m6utq1+fj4WFlinuXl5cWHNgfj/cm5eG9yNt6fnI33J+fivcnZeH8y79+OaKW5JxbIcHFxUd26dbV+/XqzLTU1VevXr1dQUFA2VgYAAAAgr7onjmxJ0tChQ9WzZ0/Vq1dPDz74oKZMmaLLly+rd+/e2V0aAAAAgDzonglbHTt21J9//qnRo0crJiZGtWrV0urVq9MtmoGs4erqqtdffz3d6ZjIGXh/ci7em5yN9ydn4/3JuXhvcjbeH+vYjMysWQgAAAAAcMg9cc0WAAAAANxthC0AAAAAsABhCwAAAAAsQNgCAAAAAAsQtpApvXr1ks1m03PPPZeuLywsTDabTb169bIb+8+tdevW5nPKlCmjKVOm3KXq7z1p78GECRPs2r/++mvZbDb973//k7Ozs/74448Mn1+xYkUNHTr0bpSa5/3z81CkSBG1bt1a+/btM8cYhqGPP/5Y9evXl4eHh3x8fFSvXj1NmTJFV65cMcclJCTo1VdfVZUqVeTm5iY/Pz8FBwdr6dKlYq2jzImKipKzs7NCQ0Pt2k+cOCGbzabo6Giz7dKlS2revLkCAwP1+++/pxuT9jij7YcffjDnSU5O1sSJE1WzZk0VLFhQRYsWVcOGDTV37lxdv379bux2rpaZz5DNZtPXX39tPr5+/bo6d+6s++67Tz///HOGY5D1bn6v8ufPL19fX7Vs2VJz5sxRamqqOa5MmTLpPjMlS5bMxspzt0ceecTud6ybbdmyRTabzfy8PPvss3J2dtbixYvTjb1y5YrCw8NVvnx5ubm5qVixYmratKm++eYbu3FHjx5V7969VbJkSbm6uqps2bLq3Lmzdu/enfU7lwcQtpBppUqV0sKFC3X16lWz7dq1a1qwYIFKly5tN7Z169Y6e/as3fbll1/e7ZLvaW5ubnrnnXd08eLFdH2PPvqoihQponnz5qXr27x5s44ePaq+ffvejTLvCTd/HtavX698+fKpXbt2Zn/37t01ePBgPfbYY9q4caOio6P12muv6ZtvvtHatWslSXFxcXrooYf02WefKTw8XD/++KM2b96sjh07avjw4YqPj8+u3ctVZs+erRdffFGbN2/WmTNnbjnuzz//VPPmzXX58mVt2bLltr8Irlu3Lt33Xd26dSX9HbRCQkI0YcIE9e/fX9u3b9fOnTsVFham6dOn68CBA1m+j3nRv32GbnblyhU9+uij2rVrl7Zu3ar777//Lld7b0t7r06cOKHvvvtOzZs316BBg9SuXTvduHHDHDd27Fi7z8xPP/2UjVXnbn379lVkZKR+//33dH1z585VvXr1VKNGDV25ckULFy7U8OHDNWfOnHRjn3vuOS1dulTTp0/XoUOHtHr1anXo0EHnz583x+zevVt169bVr7/+qo8++ki//PKLli1bpipVquill16ydD9zq3vmPlv47+rUqaPffvtNS5cuVdeuXSVJS5cuVenSpVW2bFm7sa6urvLz88uOMvF/goODdfToUY0fP14TJ06068ufP7+6d++uiIgIvfLKK3Z9c+bMUf369VWtWrW7WW6edvPnwc/PTyNHjlTjxo31559/auPGjZo/f76+/vprPfbYY+ZzypQpo0cffVQJCQmSpFdeeUUnTpzQr7/+Kn9/f3NcpUqV1LlzZ7m5ud3dncqFEhMT9dVXX2n37t2KiYnJ8Odfkk6fPq2WLVvqvvvu0zfffCMPD4/bzlukSJFbft9NmTJFmzdv1u7du1W7dm2zvVy5cnrqqaeUnJz833bqHnG7z1CxYsXMcXFxcQoNDVViYqK2bt3K/4eywc3v1X333ac6deqoQYMGatGihSIiItSvXz9JkqenJ+9PFmnXrp2KFSumiIgIjRo1ymxPTEzU4sWL9e6770qSFi9erMDAQI0cOVL+/v46ffq0SpUqZY5fvny5pk6dqrZt20r6+/9DaX84kv4+C6NXr16qWLGitmzZIien/3/MplatWho0aJDVu5orcWQLDunTp4/mzp1rPp4zZ4569+6djRXhVpydnTVu3DhNnz49w7929e3bV0eOHNHmzZvNtsTERC1ZsoSjWhZKTEzUF198oQoVKqhIkSKaP3++KleubBe00thsNnl7eys1NVULFy5U165d7YJWGg8PD+XLx9/O/s2iRYtUpUoVVa5cWd26ddOcOXPSnX55+PBhNWzYUIGBgfr222//NWj9m/nz5ys4ONguaKXJnz+/3N3d/9P896J/fobSxMTEqGnTppKk77//nl/kc5CHH35YNWvW1NKlS7O7lDwpX7586tGjhyIiIuy+0xYvXqyUlBR17txZ0t9H9rt16yZvb2+1adNGERERdvP4+fnp22+/1aVLlzJ8nejoaB04cEAvvfSSXdBK4+Pjk2X7lJcQtuCQbt26aevWrTp58qROnjypbdu2qVu3bunGrVy5Uh4eHnbbuHHjsqHie9sTTzyhWrVq6fXXX0/XFxgYqAYNGtidSrBo0SIZhqFOnTrdzTLzvJs/D56enlq+fLm++uorOTk56ciRI6pcufJtn//XX3/p4sWLqlKlyl2qOG9K+0VD+vtUp/j4eH3//fd2Y3r06KEKFSpo8eLFcnV1zdS8Dz30ULrvuzRHjhzhfcsCt/sMpRk0aJCSk5MVGRnJL305UJUqVXTixAnz8YgRI+w+M9OmTcu+4vKAPn366LfffrP7Tps7d67at28vb29vHTlyRD/88IM6duwo6e/f5+bOnWsXzj7++GNt375dRYoU0QMPPKAhQ4Zo27ZtZv+RI0ckie80BxG24JBixYopNDRUERERmjt3rkJDQ1W0aNF045o3b67o6Gi7LaPFNWC9d955R/PmzdPBgwfT9fXp00dLliwx/4o1Z84cPfXUU/L09LzbZeZpN38edu7cqZCQELVp00YnT57M1MIWLH7x3x0+fFg7d+40/8KbL18+dezYUbNnz7Yb9+ijj2rLli0O/QX+q6++Svd9l4b3Lmvc7jOUpl27duZ1JMh5DMOQzWYzHw8bNszuM9OjR49srC73q1Klih566CHzD6hHjx7Vli1bzDNV5syZo5CQEPN3trZt2yo+Pl4bNmww52jSpImOHTum9evXq0OHDjpw4IAaN26sN998UxLfZ3eK807gsD59+mjAgAGSpA8//DDDMe7u7qpQocLdLAu30KRJE4WEhCg8PNxcMTJNp06dNGTIEC1atEhNmjTRtm3bNH78+OwpNA/75+fh008/lbe3tz755BNVqlRJhw4duu3zixUrJh8fn38dh1ubPXu2bty4YXcapmEYcnV11QcffGC2vfrqq6pRo4a6dOkiwzD09NNP/+vcpUqVuuX3XWbeX/y7232G3nrrLUl/LzTz6KOPqk+fPjIMgxVVc5iDBw/aXd9dtGhRfk/IYn379tWLL76oDz/8UHPnzlX58uXVtGlTpaSkaN68eYqJibE75TwlJUVz5sxRixYtzLb8+fOrcePGaty4sUaMGKG33npLY8eO1YgRI1SpUiVJ0qFDhzI8NRoZ48gWHNa6dWslJyfr+vXrCgkJye5ykAkTJkzQihUrFBUVZdfu6empp556SnPmzNHcuXNVqVIlNW7cOJuqvHfYbDY5OTnp6tWr6tKli3799dd0S+tKf4eB+Ph4OTk5qVOnTpo/f36GK+glJibarfIFezdu3NBnn32mSZMm2f0lfe/evfL390+3Uuprr72mMWPGqGvXrvrqq6/+02t36dJF69aty3CltevXr+vy5cv/af571c2foZv17NlTERERGj58uN57771sqg7/tGHDBu3fv1/t27fP7lLytKefflpOTk5asGCBPvvsM/Xp00c2m828Duunn36y+w788ssvtXTpUsXFxd1yzsDAQN24cUPXrl1TrVq1FBgYqEmTJtkt5Z/mdvPcyziyBYc5Ozubp6Q5OztnOCYpKUkxMTF2bfny5bM75fCPP/6wO91GkgICAlSoUKGsLRiqXr26unbtmuE58X379lXjxo118OBBjRgxIhuqy/tu/jxcvHhRH3zwgRITE/XII4+oadOmWrZsmTp37qxRo0apVatWKlasmPbv36/JkyfrxRdf1OOPP663335bmzZtUv369fX222+rXr16yp8/v7Zs2aLx48dr165dXKdyCytXrtTFixfVt29feXt72/W1b99es2fPTnePmldffVXOzs7q2rWrUlNTzdMPM3L+/Pl033c+Pj5yc3PT4MGDtWrVKrVo0UJvvvmmGjVqJE9PT+3evVvvvPOOZs+erVq1amXZvuZVt/sM/VP37t3l5OSknj17yjAMDRs2zOw7fvx4uv/vVKxYkYVKslDae5WSkqLY2FitXr1a48ePV7t27ThV0GIeHh7q2LGjwsPDlZCQYJ7NMnv2bIWGhqpmzZp24wMDAzVkyBDNnz9fYWFhatasmTp37qx69eqpSJEi+uWXX/TKK6+oefPm8vLykvT3dWDBwcFq3Lixed/HxMRErVixQmvXrk13HSwkGUAm9OzZ03jsscdu2f/YY48ZPXv2NMdKSrdVrlzZHB8QEJDhmM8//9ziPbk3ZPR+HT9+3HBxcTEy+thXrlzZcHZ2Ns6cOXOXKrx3/PPz4OnpaTzwwAPGkiVLzDEpKSnGzJkzjQceeMAoWLCg4eXlZdStW9eYOnWqceXKFXNcXFycMXLkSKNixYqGi4uL4evrawQHBxvLli0zUlNTs2P3coV27doZbdu2zbBvx44dhiRj7969hiTjp59+sut/5513DGdnZ2P+/PnG8ePH7cakPc5o+/LLL805rl27ZowfP96oXr264ebmZhQuXNho2LChERERYVy/ft2q3c4zMvMZkmQsW7bM7nkLFiwwnJ2djQkTJphjMtq2bNlyN3cnT7v5vcqXL59RrFgxIzg42JgzZ46RkpJijgsICDAmT56cfYXmYdu3bzckmd95MTExRr58+YxFixZlOP755583ateubRiGYYwbN84ICgoyChcubLi5uRnlypUzBg4caPz11192zzl8+LDRo0cPw9/f33BxcTECAgKMzp07Gz/++KO1O5dL2QyDq90AAAAAIKtxzRYAAAAAWICwBQAAAAAWIGwBAAAAgAUIWwAAAABgAcIWAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAN7HZbPr666+zuwwAQB5A2AIA3FNiYmL04osvqly5cnJ1dVWpUqX0yCOPaP369dldGgAgj8mX3QUAAHC3nDhxQg0bNpSPj4/effddVa9eXdevX9eaNWsUFhamQ4cOZXeJAIA8hCNbAIB7xgsvvCCbzaadO3eqffv2qlSpkqpVq6ahQ4fqhx9+yPA5I0aMUKVKlVSwYEGVK1dOr732mq5fv2727927V82bN5enp6e8vLxUt25d7d69W5J08uRJPfLIIypUqJDc3d1VrVo1ffvtt3dlXwEA2Y8jWwCAe8KFCxe0evVqvf3223J3d0/X7+Pjk+HzPD09FRERIX9/f+3fv1/PPPOMPD09NXz4cElS165dVbt2bc2cOVPOzs6Kjo5W/vz5JUlhYWFKTk7W5s2b5e7url9++UUeHh6W7SMAIGchbAEA7glHjx6VYRiqUqWKQ88bNWqU+d9lypTRyy+/rIULF5ph69SpUxo2bJg5b8WKFc3xp06dUvv27VW9enVJUrly5f7rbgAAchFOIwQA3BMMw7ij53311Vdq2LCh/Pz85OHhoVGjRunUqVNm/9ChQ9WvXz8FBwdrwoQJ+u2338y+gQMH6q233lLDhg31+uuva9++ff95PwAAuQdhCwBwT6hYsaJsNptDi2BERUWpa9euatu2rVauXKmffvpJr776qpKTk80xY8aM0YEDBxQaGqoNGzYoMDBQy5YtkyT169dPx44dU/fu3bV//37Vq1dP06dPz/J9AwDkTDbjTv/UBwBALtOmTRvt379fhw8fTnfdVlxcnHx8fGSz2bRs2TI9/vjjmjRpkmbMmGF3tKpfv35asmSJ4uLiMnyNzp076/Lly1q+fHm6vvDwcK1atYojXABwj+DIFgDgnvHhhx8qJSVFDz74oP73v//pyJEjOnjwoKZNm6agoKB04ytWrKhTp05p4cKF+u233zRt2jTzqJUkXb16VQMGDNCmTZt08uRJbdu2Tbt27VLVqlUlSYMHD9aaNWt0/Phx/fjjj9q4caPZBwDI+1ggAwBwzyhXrpx+/PFHvf3223rppZd09uxZFStWTHXr1tXMmTPTjX/00Uc1ZMgQDRgwQElJSQoNDdVrr72mMWPGSJKcnZ11/vx59ejRQ7GxsSpatKiefPJJvfHGG5KklJQUhYWF6ffff5eXl5dat26tyZMn381dBgBkI04jBAAAAAALcBohAAAAAFiAsAUAAAAAFiBsAQAAAIAFCFsAAAAAYAHCFgAAAABYgLAFAAAAABYgbAEAAACABQhbAAAAAGABwhYAAAAAWICwBQAAAAAWIGwBAAAAgAX+HwK02P9Hym7JAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.title(\"Class Distribution in HAM10000 Dataset\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample to make sure everything is fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m mask_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../HAM10000/masks/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_segmentation.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      9\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 10\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert BGR to RGB for correct display\u001b[39;00m\n\u001b[0;32m     11\u001b[0m mask \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(mask_path, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)  \u001b[38;5;66;03m# Load mask as grayscale\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Display\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Load and display a sample image, mask, and label\n",
    "sample = metadata.iloc[25]  # First row\n",
    "image_id = sample[\"image\"]\n",
    "label = classes[sample[classes].values.argmax()]  # Get the class with value 1\n",
    "\n",
    "# Load image and mask\n",
    "image_path = f\"../HAM10000/images/{image_id}.jpg\"\n",
    "mask_path = f\"../HAM10000/masks/{image_id}_segmentation.png\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB for correct display\n",
    "mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load mask as grayscale\n",
    "\n",
    "# Display\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(image)\n",
    "plt.title(f\"Image (Label: {label})\")\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(mask, cmap=\"gray\")\n",
    "plt.title(\"Mask\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAIN / TEST / VALIDATION SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Split Sizes:\n",
      "Training set: 7010 samples (70.0%)\n",
      "Validation set: 1503 samples (15.0%)\n",
      "Test set: 1502 samples (15.0%)\n",
      "\n",
      "Class Distribution in Training Set:\n",
      "label\n",
      "NV       4693\n",
      "MEL       779\n",
      "BKL       769\n",
      "BCC       360\n",
      "AKIEC     229\n",
      "VASC       99\n",
      "DF         81\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Distribution in Validation Set:\n",
      "label\n",
      "NV       1006\n",
      "MEL       167\n",
      "BKL       165\n",
      "BCC        77\n",
      "AKIEC      49\n",
      "VASC       22\n",
      "DF         17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class Distribution in Test Set:\n",
      "label\n",
      "NV       1006\n",
      "MEL       167\n",
      "BKL       165\n",
      "BCC        77\n",
      "AKIEC      49\n",
      "VASC       21\n",
      "DF         17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test+val (70% train, 30% test+val)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_data, test_val_data = train_test_split(\n",
    "    metadata,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=metadata[\"label\"]\n",
    ")\n",
    "\n",
    "# Split test+val into test and val (15% test, 15% val)\n",
    "test_data, val_data = train_test_split(\n",
    "    test_val_data,\n",
    "    test_size=0.5,  # 0.5 of 30% = 15% of total\n",
    "    random_state=42,\n",
    "    stratify=test_val_data[\"label\"]\n",
    ")\n",
    "\n",
    "# Print the sizes of each split\n",
    "print(\"\\nDataset Split Sizes:\")\n",
    "print(f\"Training set: {len(train_data)} samples ({len(train_data)/len(metadata)*100:.1f}%)\")\n",
    "print(f\"Validation set: {len(val_data)} samples ({len(val_data)/len(metadata)*100:.1f}%)\")\n",
    "print(f\"Test set: {len(test_data)} samples ({len(test_data)/len(metadata)*100:.1f}%)\")\n",
    "\n",
    "# Check class distribution in each split\n",
    "print(\"\\nClass Distribution in Training Set:\")\n",
    "print(train_data[\"label\"].value_counts())\n",
    "print(\"\\nClass Distribution in Validation Set:\")\n",
    "print(val_data[\"label\"].value_counts())\n",
    "print(\"\\nClass Distribution in Test Set:\")\n",
    "print(test_data[\"label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create empty folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder structure created successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Define the classes\n",
    "classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "\n",
    "# Define the base paths\n",
    "base_image_path = \"../HAM10000/images/\"\n",
    "base_mask_path = \"../HAM10000/masks/\"\n",
    "\n",
    "# Define the splits\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "\n",
    "# Create the new folder structure\n",
    "for split in splits:\n",
    "    for class_name in classes:\n",
    "        # Create image folders (e.g., images/train/MEL/)\n",
    "        image_split_class_path = os.path.join(base_image_path, split, class_name)\n",
    "        os.makedirs(image_split_class_path, exist_ok=True)\n",
    "        \n",
    "        # Create mask folders (e.g., masks/train/MEL/)\n",
    "        mask_split_class_path = os.path.join(base_mask_path, split, class_name)\n",
    "        os.makedirs(mask_split_class_path, exist_ok=True)\n",
    "\n",
    "print(\"Folder structure created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT DATA INTO SPECIFIC FOLDERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files moved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Function to move files for a given split\n",
    "def move_files(data, split_name):\n",
    "    for _, row in data.iterrows():\n",
    "        image_id = row[\"image\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        # Source paths\n",
    "        src_image_path = f\"../HAM10000/images/{image_id}.jpg\"\n",
    "        src_mask_path = f\"../HAM10000/masks/{image_id}_segmentation.png\"\n",
    "        \n",
    "        # Destination paths\n",
    "        dst_image_path = f\"../HAM10000/images/{split_name}/{label}/{image_id}.jpg\"\n",
    "        dst_mask_path = f\"../HAM10000/masks/{split_name}/{label}/{image_id}_segmentation.png\"\n",
    "        \n",
    "        # Move files (copy then delete to be safe)\n",
    "        if os.path.exists(src_image_path) and os.path.exists(src_mask_path):\n",
    "            shutil.copy2(src_image_path, dst_image_path)\n",
    "            shutil.copy2(src_mask_path, dst_mask_path)\n",
    "            os.remove(src_image_path)  # Remove the original file\n",
    "            os.remove(src_mask_path)\n",
    "        else:\n",
    "            print(f\"Missing file for {image_id} in {split_name} split\")\n",
    "\n",
    "# Move files for each split\n",
    "move_files(train_data, \"train\")\n",
    "move_files(val_data, \"val\")\n",
    "move_files(test_data, \"test\")\n",
    "\n",
    "print(\"Files moved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Precoessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking train/MEL...\n",
      "Initial: 779 images, 779 masks\n",
      "After cleanup: 779 images, 779 masks\n",
      "\n",
      "Checking train/NV...\n",
      "Initial: 4693 images, 4693 masks\n",
      "After cleanup: 4693 images, 4693 masks\n",
      "\n",
      "Checking train/BCC...\n",
      "Initial: 360 images, 360 masks\n",
      "After cleanup: 360 images, 360 masks\n",
      "\n",
      "Checking train/AKIEC...\n",
      "Initial: 229 images, 229 masks\n",
      "After cleanup: 229 images, 229 masks\n",
      "\n",
      "Checking train/BKL...\n",
      "Initial: 769 images, 769 masks\n",
      "After cleanup: 769 images, 769 masks\n",
      "\n",
      "Checking train/DF...\n",
      "Initial: 81 images, 81 masks\n",
      "After cleanup: 81 images, 81 masks\n",
      "\n",
      "Checking train/VASC...\n",
      "Initial: 99 images, 99 masks\n",
      "After cleanup: 99 images, 99 masks\n",
      "\n",
      "Checking val/MEL...\n",
      "Initial: 167 images, 167 masks\n",
      "After cleanup: 167 images, 167 masks\n",
      "\n",
      "Checking val/NV...\n",
      "Initial: 1006 images, 1006 masks\n",
      "After cleanup: 1006 images, 1006 masks\n",
      "\n",
      "Checking val/BCC...\n",
      "Initial: 77 images, 77 masks\n",
      "After cleanup: 77 images, 77 masks\n",
      "\n",
      "Checking val/AKIEC...\n",
      "Initial: 49 images, 49 masks\n",
      "After cleanup: 49 images, 49 masks\n",
      "\n",
      "Checking val/BKL...\n",
      "Initial: 165 images, 165 masks\n",
      "After cleanup: 165 images, 165 masks\n",
      "\n",
      "Checking val/DF...\n",
      "Initial: 17 images, 17 masks\n",
      "After cleanup: 17 images, 17 masks\n",
      "\n",
      "Checking val/VASC...\n",
      "Initial: 22 images, 22 masks\n",
      "After cleanup: 22 images, 22 masks\n",
      "\n",
      "Checking test/MEL...\n",
      "Initial: 167 images, 167 masks\n",
      "After cleanup: 167 images, 167 masks\n",
      "\n",
      "Checking test/NV...\n",
      "Initial: 1006 images, 1006 masks\n",
      "After cleanup: 1006 images, 1006 masks\n",
      "\n",
      "Checking test/BCC...\n",
      "Initial: 77 images, 77 masks\n",
      "After cleanup: 77 images, 77 masks\n",
      "\n",
      "Checking test/AKIEC...\n",
      "Initial: 49 images, 49 masks\n",
      "After cleanup: 49 images, 49 masks\n",
      "\n",
      "Checking test/BKL...\n",
      "Initial: 165 images, 165 masks\n",
      "After cleanup: 165 images, 165 masks\n",
      "\n",
      "Checking test/DF...\n",
      "Initial: 17 images, 17 masks\n",
      "After cleanup: 17 images, 17 masks\n",
      "\n",
      "Checking test/VASC...\n",
      "Initial: 21 images, 21 masks\n",
      "After cleanup: 21 images, 21 masks\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define the splits and classes\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "\n",
    "# Base paths\n",
    "base_image_path = \"../HAM10000/images/\"\n",
    "base_mask_path = \"../HAM10000/masks/\"\n",
    "\n",
    "# Check for corrupt files and remove them\n",
    "for split in splits:\n",
    "    for class_name in classes:\n",
    "        image_dir = os.path.join(base_image_path, split, class_name)\n",
    "        mask_dir = os.path.join(base_mask_path, split, class_name)\n",
    "        \n",
    "        image_files = os.listdir(image_dir)\n",
    "        mask_files = os.listdir(mask_dir)\n",
    "        \n",
    "        print(f\"\\nChecking {split}/{class_name}...\")\n",
    "        print(f\"Initial: {len(image_files)} images, {len(mask_files)} masks\")\n",
    "        \n",
    "        # Check each image\n",
    "        for image_file in image_files:\n",
    "            image_path = os.path.join(image_dir, image_file)\n",
    "            mask_file = image_file.replace(\".jpg\", \"_segmentation.png\")\n",
    "            mask_path = os.path.join(mask_dir, mask_file)\n",
    "            \n",
    "            # Load image and mask\n",
    "            image = cv2.imread(image_path)\n",
    "            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "            \n",
    "            # Check if either file is corrupt or missing\n",
    "            if image is None or mask is None or mask_file not in mask_files:\n",
    "                print(f\"Corrupt or missing pair: {image_file} in {split}/{class_name}\")\n",
    "                if os.path.exists(image_path):\n",
    "                    os.remove(image_path)\n",
    "                if os.path.exists(mask_path):\n",
    "                    os.remove(mask_path)\n",
    "        \n",
    "        # Recount after removal\n",
    "        image_files = os.listdir(image_dir)\n",
    "        mask_files = os.listdir(mask_dir)\n",
    "        print(f\"After cleanup: {len(image_files)} images, {len(mask_files)} masks\")\n",
    "        \n",
    "        # Final check for mismatch\n",
    "        if len(image_files) != len(mask_files):\n",
    "            print(f\"Warning: Mismatch in {split}/{class_name} after cleanup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define image size (e.g., 224x224, common for CNNs like ResNet)\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# Define transformations for images\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),  # Data augmentation for training\n",
    "    transforms.RandomRotation(10),      # Data augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet stats\n",
    "])\n",
    "\n",
    "val_test_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Define transformations for masks (resize only, no normalization)\n",
    "mask_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(IMG_SIZE, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 7010\n",
      "Validation dataset size: 1503\n",
      "Test dataset size: 1502\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "class SkinCancerDataset(Dataset):\n",
    "    def __init__(self, split, transform=None, mask_transform=None):\n",
    "        self.split = split  # 'train', 'val', or 'test'\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "        self.classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Collect all image paths and labels\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for class_name in self.classes:\n",
    "            image_dir = f\"../HAM10000/images/{split}/{class_name}/\"\n",
    "            for image_file in os.listdir(image_dir):\n",
    "                self.image_paths.append(os.path.join(image_dir, image_file))\n",
    "                self.labels.append(self.class_to_idx[class_name])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        \n",
    "        # Load mask\n",
    "        mask_path = image_path.replace(\"images\", \"masks\").replace(\".jpg\", \"_segmentation.png\")\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "            mask = (mask > 0).float()  # Ensure mask is binary (0 or 1)\n",
    "        \n",
    "        label = self.labels[idx]\n",
    "        return image, mask, label\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SkinCancerDataset(\"train\", transform=train_transforms, mask_transform=mask_transforms)\n",
    "val_dataset = SkinCancerDataset(\"val\", transform=val_test_transforms, mask_transform=mask_transforms)\n",
    "test_dataset = SkinCancerDataset(\"test\", transform=val_test_transforms, mask_transform=mask_transforms)\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader creation took 0.00 seconds\n",
      "Val loader creation took 0.00 seconds\n",
      "Test loader creation took 0.00 seconds\n",
      "Loading first batch took 0.34 seconds\n",
      "Batch shapes - Images: torch.Size([32, 3, 224, 224]), Masks: torch.Size([32, 1, 224, 224]), Labels: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "\n",
    "# Define batch size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Create DataLoaders with num_workers=0 to avoid multiprocessing issues\n",
    "start_time = time.time()\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "print(f\"Train loader creation took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(f\"Val loader creation took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "start_time = time.time()\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "print(f\"Test loader creation took {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Verify a batch\n",
    "start_time = time.time()\n",
    "images, masks, labels = next(iter(train_loader))\n",
    "print(f\"Loading first batch took {time.time() - start_time:.2f} seconds\")\n",
    "print(f\"Batch shapes - Images: {images.shape}, Masks: {masks.shape}, Labels: {labels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "GPU Count: 0\n",
      "GPU Name: No GPU detected\n",
      "Total parameters: 6,447,143\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SkinCancerCNN(nn.Module):\n",
    "    def __init__(self, num_classes=7):\n",
    "        super(SkinCancerCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),  # Output: 32 x 224 x 224\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 32 x 112 x 112\n",
    "\n",
    "            # Block 2\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # Output: 64 x 112 x 112\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 64 x 56 x 56\n",
    "\n",
    "            # Block 3\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),# Output: 128 x 56 x 56\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),       # Output: 128 x 28 x 28\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)  # Do the pattern-finding steps\n",
    "        x = self.classifier(x)  # Make the final guess\n",
    "        return x\n",
    "\n",
    "# Create the model and check if we can use a GPU (faster) or CPU (slower)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model = SkinCancerCNN(num_classes=7).to(device)\n",
    "# Example: Move input data to GPU before passing it to the model\n",
    "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "output = model(input_tensor)  # Now runs on GPU\n",
    "\n",
    "\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Count:\", torch.cuda.device_count())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "\n",
    "# Count how many \"settings\" the model has\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: tensor([ 1.2855,  0.2134,  2.7817,  4.3731,  1.3022, 12.3633, 10.1154])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Get the labels from the training data\n",
    "train_labels = []\n",
    "for _, _, label in train_dataset:  # We only need the labels, not the images or masks\n",
    "    train_labels.append(label)\n",
    "\n",
    "# Calculate weights for each class (to balance the dataset)\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  # This makes sure rare classes get more importance\n",
    "    classes=np.arange(7),     # The 7 classes (0=MEL, 1=NV, 2=BCC, 3=AKIEC, 4=BKL, 5=DF, 6=VASC)\n",
    "    y=train_labels            # The labels from the training data\n",
    ")\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "print(\"Class weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Create a random tensor and move it to GPU\n",
    "tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "print(tensor.device)  # Should print \"cuda:0\"\n",
    "\n",
    "# Move model to GPU\n",
    "model.to(device)\n",
    "\n",
    "# Generate a random input and ensure model runs on GPU\n",
    "input_tensor = torch.randn(1, 3, 224, 224).to(device)\n",
    "output = model(input_tensor)\n",
    "print(output.device)  # Should print \"cuda:0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1/10, Training Mistakes: 1.8179, Validation Mistakes: 1.1623, Validation Correct: 63.41%\n",
      "Round 2/10, Training Mistakes: 1.6686, Validation Mistakes: 1.4971, Validation Correct: 38.52%\n",
      "Round 3/10, Training Mistakes: 1.6113, Validation Mistakes: 1.1502, Validation Correct: 59.81%\n",
      "Round 4/10, Training Mistakes: 1.5025, Validation Mistakes: 1.1704, Validation Correct: 54.49%\n",
      "Round 5/10, Training Mistakes: 1.4616, Validation Mistakes: 1.3167, Validation Correct: 48.90%\n",
      "Round 6/10, Training Mistakes: 1.4031, Validation Mistakes: 1.2076, Validation Correct: 49.90%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m  \u001b[38;5;66;03m# Keep track of how many mistakes the model makes\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Show the model each batch of training images\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We don't need the masks for classification\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Move data to GPU/CPU\u001b[39;49;00m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Reset the learning process\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[8], line 29\u001b[0m, in \u001b[0;36mSkinCancerDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[idx]\n\u001b[1;32m---> 29\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)  \u001b[38;5;66;03m# Convert BGR to RGB\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Load mask\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Set up the \"scoring system\" and \"learning method\"\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)  # Scoring system that uses the weights\n",
    "\n",
    "# Method to help the model learn with L2 regularization (weight_decay)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.001)  # Adding L2 regularization (weight_decay)\n",
    "\n",
    "# Teach the model for 10 rounds\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Tell the model we're in \"learning mode\"\n",
    "    total_loss = 0.0  # Keep track of how many mistakes the model makes\n",
    "    \n",
    "    # Show the model each batch of training images\n",
    "    for images, _, labels in train_loader:  # We don't need the masks for classification\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to GPU/CPU\n",
    "        \n",
    "        optimizer.zero_grad()  # Reset the learning process\n",
    "        guesses = model(images)  # Let the model guess the cancer type\n",
    "        loss = criterion(guesses, labels)  # Check how wrong the guesses are\n",
    "        loss.backward()  # Tell the model what it got wrong\n",
    "        optimizer.step()  # Help the model learn from its mistakes\n",
    "        \n",
    "        total_loss += loss.item()  # Add up the mistakes\n",
    "    \n",
    "    # Check how well the model is doing on the validation images\n",
    "    model.eval()  # Tell the model we're in \"testing mode\"\n",
    "    val_loss = 0.0  # Track mistakes on validation data\n",
    "    correct = 0  # Count correct guesses\n",
    "    total = 0  # Count total guesses\n",
    "    with torch.no_grad():  # Don't learn, just test\n",
    "        for images, _, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            guesses = model(images)\n",
    "            loss = criterion(guesses, labels)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Count how many guesses were correct\n",
    "            best_guess = guesses.argmax(dim=1)  # Pick the highest score as the guess\n",
    "            total += labels.size(0)  # Add up the number of images\n",
    "            correct += (best_guess == labels).sum().item()  # Count correct guesses\n",
    "    \n",
    "    # Print how the model did in this round\n",
    "    print(f\"Round {epoch+1}/{num_epochs}, Training Mistakes: {total_loss/len(train_loader):.4f}, \"\n",
    "          f\"Validation Mistakes: {val_loss/len(val_loader):.4f}, Validation Correct: {100 * correct / total:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
